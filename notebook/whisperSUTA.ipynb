{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allen172/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import whisper\n",
    "from whisper.audio import (\n",
    "    log_mel_spectrogram,\n",
    "    pad_or_trim,\n",
    "    load_audio,\n",
    ")\n",
    "\n",
    "import jiwer\n",
    "from tqdm import tqdm\n",
    "from main import *\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder.conv1.weight', 'encoder.conv1.bias', 'encoder.conv2.weight', 'encoder.conv2.bias', 'encoder.blocks.0.attn_ln.weight', 'encoder.blocks.0.attn_ln.bias', 'encoder.blocks.0.mlp_ln.weight', 'encoder.blocks.0.mlp_ln.bias', 'encoder.blocks.1.attn_ln.weight', 'encoder.blocks.1.attn_ln.bias', 'encoder.blocks.1.mlp_ln.weight', 'encoder.blocks.1.mlp_ln.bias', 'encoder.blocks.2.attn_ln.weight', 'encoder.blocks.2.attn_ln.bias', 'encoder.blocks.2.mlp_ln.weight', 'encoder.blocks.2.mlp_ln.bias', 'encoder.blocks.3.attn_ln.weight', 'encoder.blocks.3.attn_ln.bias', 'encoder.blocks.3.mlp_ln.weight', 'encoder.blocks.3.mlp_ln.bias', 'encoder.blocks.4.attn_ln.weight', 'encoder.blocks.4.attn_ln.bias', 'encoder.blocks.4.mlp_ln.weight', 'encoder.blocks.4.mlp_ln.bias', 'encoder.blocks.5.attn_ln.weight', 'encoder.blocks.5.attn_ln.bias', 'encoder.blocks.5.mlp_ln.weight', 'encoder.blocks.5.mlp_ln.bias', 'encoder.ln_post.weight', 'encoder.ln_post.bias', 'decoder.blocks.0.attn_ln.weight', 'decoder.blocks.0.attn_ln.bias', 'decoder.blocks.0.cross_attn_ln.weight', 'decoder.blocks.0.cross_attn_ln.bias', 'decoder.blocks.0.mlp_ln.weight', 'decoder.blocks.0.mlp_ln.bias', 'decoder.blocks.1.attn_ln.weight', 'decoder.blocks.1.attn_ln.bias', 'decoder.blocks.1.cross_attn_ln.weight', 'decoder.blocks.1.cross_attn_ln.bias', 'decoder.blocks.1.mlp_ln.weight', 'decoder.blocks.1.mlp_ln.bias', 'decoder.blocks.2.attn_ln.weight', 'decoder.blocks.2.attn_ln.bias', 'decoder.blocks.2.cross_attn_ln.weight', 'decoder.blocks.2.cross_attn_ln.bias', 'decoder.blocks.2.mlp_ln.weight', 'decoder.blocks.2.mlp_ln.bias', 'decoder.blocks.3.attn_ln.weight', 'decoder.blocks.3.attn_ln.bias', 'decoder.blocks.3.cross_attn_ln.weight', 'decoder.blocks.3.cross_attn_ln.bias', 'decoder.blocks.3.mlp_ln.weight', 'decoder.blocks.3.mlp_ln.bias', 'decoder.blocks.4.attn_ln.weight', 'decoder.blocks.4.attn_ln.bias', 'decoder.blocks.4.cross_attn_ln.weight', 'decoder.blocks.4.cross_attn_ln.bias', 'decoder.blocks.4.mlp_ln.weight', 'decoder.blocks.4.mlp_ln.bias', 'decoder.blocks.5.attn_ln.weight', 'decoder.blocks.5.attn_ln.bias', 'decoder.blocks.5.cross_attn_ln.weight', 'decoder.blocks.5.cross_attn_ln.bias', 'decoder.blocks.5.mlp_ln.weight', 'decoder.blocks.5.mlp_ln.bias', 'decoder.ln.weight', 'decoder.ln.bias']\n"
     ]
    }
   ],
   "source": [
    "# collect trainable params\n",
    "params = []\n",
    "names = []\n",
    "for nm, m in model.named_modules():\n",
    "    # print(str(nm).split('.'))\n",
    "    trainable = ['weight', 'bias']\n",
    "    # train_LN\n",
    "    if isinstance(m, nn.LayerNorm):\n",
    "        for np, p in m.named_parameters():\n",
    "            if np in trainable:  \n",
    "                p.requires_grad = True\n",
    "                params.append(p)\n",
    "                names.append(f\"{nm}.{np}\")\n",
    "    # train_feature\n",
    "    if len(str(nm).split('.')) > 1:\n",
    "        if str(nm).split('.')[0] == 'encoder' and (str(nm).split('.')[1] == 'conv1' or str(nm).split('.')[1] == 'conv2'):\n",
    "            for np, p in m.named_parameters():\n",
    "                p.requires_grad = True\n",
    "                params.append(p)\n",
    "                names.append(f\"{nm}.{np}\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio\n",
    "model = model.to(DEVICE)\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n",
    "audio = load_audio(file='./p232_001.wav')\n",
    "audio = pad_or_trim(audio)\n",
    "mel = log_mel_spectrogram(audio)\n",
    "mel = mel.unsqueeze(-1)\n",
    "mel = mel.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DecodingResult(audio_features=tensor([[-1.6826,  0.1215, -0.4236,  ...,  0.4717, -0.7290,  0.2764],\n",
       "          [-1.3369, -0.6982,  0.3635,  ...,  0.4441, -0.4841,  0.5293],\n",
       "          [-1.2100, -1.0420,  0.8184,  ...,  0.0606,  0.1081, -0.0176],\n",
       "          ...,\n",
       "          [ 0.1824, -0.4514, -0.4377,  ...,  1.0195, -0.5532,  0.7129],\n",
       "          [ 0.6265, -0.3445,  0.0033,  ...,  1.0947, -0.7920,  0.2429],\n",
       "          [ 0.8047, -0.7417,  0.4585,  ...,  0.5771, -0.7646, -0.1542]],\n",
       "         device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[4222, 869, 45856, 13], text='Please call Stella.', avg_logprob=-0.1863834500312805, no_speech_prob=0.04131714627146721, temperature=0.0, compression_ratio=0.7037037037037037)],\n",
       " [tensor([[ 5.1758e+00, -1.0000e+20, -1.0000e+20,  ...,  2.6641e+00,\n",
       "            1.3848e+00,  8.3838e-01]], device='cuda:0'),\n",
       "  tensor([[ 7.6055e+00, -1.0000e+20, -1.0000e+20,  ...,  3.8184e+00,\n",
       "            3.9199e+00,  2.9531e+00]], device='cuda:0'),\n",
       "  tensor([[-9.1699e-01, -1.0000e+20, -1.0000e+20,  ..., -3.0410e+00,\n",
       "           -2.9707e+00, -5.3359e+00]], device='cuda:0'),\n",
       "  tensor([[ 2.0406e+01, -1.0000e+20, -1.0000e+20,  ...,  9.1719e+00,\n",
       "            8.2109e+00,  8.2734e+00]], device='cuda:0'),\n",
       "  tensor([[ 7.2148e+00, -1.0000e+20, -1.0000e+20,  ...,  5.2617e+00,\n",
       "            4.6094e+00,  4.1250e+00]], device='cuda:0')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward\n",
    "mel = mel.to(DEVICE)\n",
    "outputs = model.decode(mel, options)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tensor = torch.stack(outputs[1], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 51864])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tensor=result_tensor.permute(1,0,2)\n",
    "result_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6461, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_loss = softmax_entropy(result_tensor).mean(0).mean()\n",
    "e_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_loss = mcc_loss(result_tensor, reweight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "loss += e_loss * 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]    optimizer: <class 'torch.optim.adamw.AdamW'>\n",
      "[INFO]    scheduler: None\n"
     ]
    }
   ],
   "source": [
    "optimizer, scheduler = setup_optimizer(params, 'AdamW', lr=1e-4, scheduler=None)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DecodingResult(audio_features=tensor([[-1.6826,  0.1215, -0.4236,  ...,  0.4717, -0.7290,  0.2764],\n",
       "          [-1.3369, -0.6982,  0.3635,  ...,  0.4441, -0.4841,  0.5293],\n",
       "          [-1.2100, -1.0420,  0.8184,  ...,  0.0606,  0.1081, -0.0176],\n",
       "          ...,\n",
       "          [ 0.1824, -0.4514, -0.4377,  ...,  1.0195, -0.5532,  0.7129],\n",
       "          [ 0.6265, -0.3445,  0.0033,  ...,  1.0947, -0.7920,  0.2429],\n",
       "          [ 0.8047, -0.7417,  0.4585,  ...,  0.5771, -0.7646, -0.1542]],\n",
       "         device='cuda:0', dtype=torch.float16), language='en', language_probs=None, tokens=[4222, 869, 45856, 13], text='Please call Stella.', avg_logprob=-0.1863834500312805, no_speech_prob=0.04131714627146721, temperature=0.0, compression_ratio=0.7037037037037037)],\n",
       " [tensor([[ 5.1758e+00, -1.0000e+20, -1.0000e+20,  ...,  2.6641e+00,\n",
       "            1.3848e+00,  8.3838e-01]], device='cuda:0'),\n",
       "  tensor([[ 7.6055e+00, -1.0000e+20, -1.0000e+20,  ...,  3.8184e+00,\n",
       "            3.9199e+00,  2.9531e+00]], device='cuda:0'),\n",
       "  tensor([[-9.1699e-01, -1.0000e+20, -1.0000e+20,  ..., -3.0410e+00,\n",
       "           -2.9707e+00, -5.3359e+00]], device='cuda:0'),\n",
       "  tensor([[ 2.0406e+01, -1.0000e+20, -1.0000e+20,  ...,  9.1719e+00,\n",
       "            8.2109e+00,  8.2734e+00]], device='cuda:0'),\n",
       "  tensor([[ 7.2148e+00, -1.0000e+20, -1.0000e+20,  ...,  5.2617e+00,\n",
       "            4.6094e+00,  4.1250e+00]], device='cuda:0')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model.decode(mel, options)\n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
