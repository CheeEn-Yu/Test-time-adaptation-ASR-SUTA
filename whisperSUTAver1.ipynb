{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allens/anaconda3/envs/tta/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import whisper\n",
    "from whisper.audio import (\n",
    "    log_mel_spectrogram,\n",
    "    pad_or_trim,\n",
    "    load_audio,\n",
    ")\n",
    "\n",
    "import jiwer\n",
    "from tqdm import tqdm\n",
    "from main import *\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['encoder.conv1.weight', 'encoder.conv1.bias', 'encoder.conv2.weight', 'encoder.conv2.bias', 'encoder.blocks.0.attn_ln.weight', 'encoder.blocks.0.attn_ln.bias', 'encoder.blocks.0.mlp_ln.weight', 'encoder.blocks.0.mlp_ln.bias', 'encoder.blocks.1.attn_ln.weight', 'encoder.blocks.1.attn_ln.bias', 'encoder.blocks.1.mlp_ln.weight', 'encoder.blocks.1.mlp_ln.bias', 'encoder.blocks.2.attn_ln.weight', 'encoder.blocks.2.attn_ln.bias', 'encoder.blocks.2.mlp_ln.weight', 'encoder.blocks.2.mlp_ln.bias', 'encoder.blocks.3.attn_ln.weight', 'encoder.blocks.3.attn_ln.bias', 'encoder.blocks.3.mlp_ln.weight', 'encoder.blocks.3.mlp_ln.bias', 'encoder.blocks.4.attn_ln.weight', 'encoder.blocks.4.attn_ln.bias', 'encoder.blocks.4.mlp_ln.weight', 'encoder.blocks.4.mlp_ln.bias', 'encoder.blocks.5.attn_ln.weight', 'encoder.blocks.5.attn_ln.bias', 'encoder.blocks.5.mlp_ln.weight', 'encoder.blocks.5.mlp_ln.bias', 'encoder.ln_post.weight', 'encoder.ln_post.bias']\n"
     ]
    }
   ],
   "source": [
    "# collect trainable params\n",
    "params = []\n",
    "names = []\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for nm, m in model.named_modules():\n",
    "    # print(str(nm).split('.'))\n",
    "    trainable = ['weight', 'bias']\n",
    "    # train_LN\n",
    "    if isinstance(m, nn.LayerNorm) and str(nm).split('.')[0] == 'encoder':\n",
    "        for np, p in m.named_parameters():\n",
    "            if np in trainable:  \n",
    "                p.requires_grad = True\n",
    "                params.append(p)\n",
    "                names.append(f\"{nm}.{np}\")\n",
    "    # train_feature\n",
    "    if len(str(nm).split('.')) > 1:\n",
    "        if str(nm).split('.')[0] == 'encoder' and (str(nm).split('.')[1] == 'conv1' or str(nm).split('.')[1] == 'conv2'):\n",
    "            for np, p in m.named_parameters():\n",
    "                p.requires_grad = True\n",
    "                params.append(p)\n",
    "                names.append(f\"{nm}.{np}\")\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check trainable parameter\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(\"name: \", name)\n",
    "#     print(\"requires_grad: \", param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio\n",
    "model = model.to(DEVICE)\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n",
    "audio = load_audio(file='./p232_022.wav')\n",
    "audio = pad_or_trim(audio)\n",
    "mel = log_mel_spectrogram(audio)\n",
    "mel = mel.unsqueeze(-1)\n",
    "mel = mel.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([DecodingResult(audio_features=tensor([[-6.8994e-01,  5.6152e-01, -9.4238e-01,  ...,  2.4438e-01,\n",
       "           -4.6631e-01,  2.3331e-02],\n",
       "          [-5.1758e-01,  4.1162e-01, -6.4731e-05,  ...,  9.3115e-01,\n",
       "           -8.7305e-01,  1.8359e-01],\n",
       "          [-9.4092e-01, -2.0190e-01,  3.5303e-01,  ...,  5.2930e-01,\n",
       "           -1.8066e-01, -3.0908e-01],\n",
       "          ...,\n",
       "          [ 3.3105e-01, -6.3818e-01, -9.0723e-01,  ...,  1.0029e+00,\n",
       "           -2.2168e-01,  8.9893e-01],\n",
       "          [ 7.2314e-01, -3.7769e-01, -4.2725e-01,  ...,  1.1074e+00,\n",
       "           -3.8501e-01,  5.4004e-01],\n",
       "          [ 7.6709e-01, -7.2461e-01,  3.1763e-01,  ...,  6.4258e-01,\n",
       "           -4.7339e-01,  2.2205e-01]], device='cuda:0', dtype=torch.float16,\n",
       "         grad_fn=<UnbindBackward0>), language='en', language_probs=None, tokens=[383, 4036, 4165, 27223, 6515, 318, 531, 284, 307, 262, 1245, 286, 2208, 320, 9150, 286, 257, 1271, 286, 37469, 13], text='The actual primary rainbow observed is said to be the effect of superimposition of a number of bows.', avg_logprob=-0.04587903347882358, no_speech_prob=0.005041659343987703, temperature=0.0, compression_ratio=1.1627906976744187)],\n",
       " [tensor([[ 4.7930e+00, -1.0000e+20, -1.0000e+20,  ...,  3.5781e+00,\n",
       "            3.1816e+00,  2.5645e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.3623e+00, -1.0000e+20, -1.0000e+20,  ..., -4.5532e-01,\n",
       "           -6.5918e-01, -1.6455e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 3.0054e-01, -1.0000e+20, -1.0000e+20,  ..., -6.5088e-01,\n",
       "           -3.0444e-01, -1.7471e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[-3.5117e+00, -1.0000e+20, -1.0000e+20,  ..., -4.1289e+00,\n",
       "           -3.8574e+00, -6.5547e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 2.9629e+00, -1.0000e+20, -1.0000e+20,  ..., -7.3926e-01,\n",
       "           -8.6328e-01, -1.1006e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.7484e+01, -1.0000e+20, -1.0000e+20,  ...,  1.3602e+01,\n",
       "            1.2914e+01,  1.1664e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.1195e+01, -1.0000e+20, -1.0000e+20,  ...,  9.8828e+00,\n",
       "            9.7734e+00,  8.7812e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.8453e+01, -1.0000e+20, -1.0000e+20,  ...,  1.8125e+01,\n",
       "            1.7453e+01,  1.6297e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.3633e+01, -1.0000e+20, -1.0000e+20,  ...,  1.5648e+01,\n",
       "            1.5008e+01,  1.4484e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.2445e+01, -1.0000e+20, -1.0000e+20,  ...,  1.0773e+01,\n",
       "            1.0281e+01,  9.9844e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 4.0703e+00, -1.0000e+20, -1.0000e+20,  ...,  3.6348e+00,\n",
       "            2.6641e+00,  2.1133e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.2289e+01, -1.0000e+20, -1.0000e+20,  ...,  1.0148e+01,\n",
       "            9.8047e+00,  9.6328e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[-1.0225e+00, -1.0000e+20, -1.0000e+20,  ..., -3.0645e+00,\n",
       "           -2.6113e+00, -2.3691e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[-2.7417e-01, -1.0000e+20, -1.0000e+20,  ..., -2.7227e+00,\n",
       "           -3.3320e+00, -3.4199e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[-1.5859e+00, -1.0000e+20, -1.0000e+20,  ..., -1.8975e+00,\n",
       "           -2.6348e+00, -3.6250e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 2.0531e+01, -1.0000e+20, -1.0000e+20,  ...,  1.7156e+01,\n",
       "            1.6438e+01,  1.6453e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.2758e+01, -1.0000e+20, -1.0000e+20,  ...,  1.2180e+01,\n",
       "            1.1805e+01,  1.2875e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 7.1367e+00, -1.0000e+20, -1.0000e+20,  ...,  5.8828e+00,\n",
       "            5.3203e+00,  6.2734e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 1.4250e+01, -1.0000e+20, -1.0000e+20,  ...,  1.0867e+01,\n",
       "            1.0320e+01,  1.0258e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[-2.2925e-01, -1.0000e+20, -1.0000e+20,  ..., -1.1816e+00,\n",
       "           -1.7617e+00, -2.7168e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 2.0578e+01, -1.0000e+20, -1.0000e+20,  ...,  1.1445e+01,\n",
       "            1.1305e+01,  1.0383e+01]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>),\n",
       "  tensor([[ 7.0977e+00, -1.0000e+20, -1.0000e+20,  ...,  6.0273e+00,\n",
       "            5.8008e+00,  5.2617e+00]], device='cuda:0',\n",
       "         grad_fn=<AsStridedBackward0>)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward\n",
    "mel = mel.to(DEVICE)\n",
    "outputs = model.decode(mel, options)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate loss and adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]    optimizer: <class 'torch.optim.adamw.AdamW'>\n",
      "[INFO]    scheduler: None\n"
     ]
    }
   ],
   "source": [
    "optimizer, scheduler = setup_optimizer(params, 'AdamW', lr=3e-4, scheduler=None)\n",
    "outputs = model.decode(mel, options)\n",
    "result_tensor = torch.stack(outputs[1], dim=0)\n",
    "result_tensor=result_tensor.permute(1,0,2) # torch.Size([1, 5, 51864])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2301, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_loss = softmax_entropy(result_tensor).mean(0).mean()\n",
    "# c_loss = mcc_loss(result_tensor, reweight=False)\n",
    "loss = 0\n",
    "loss += e_loss\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "if scheduler is not None: \n",
    "    scheduler.step()\n",
    "model.zero_grad()\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model.decode(mel, options)\n",
    "#     print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual primary rainbow observed is said to be the effect of superimposition of a number of bows.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model.decode(mel, options)\n",
    "    print(outputs[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for np, p in model.encoder.conv1.named_parameters():\n",
    "#     if np in trainable:\n",
    "#         print(p.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
