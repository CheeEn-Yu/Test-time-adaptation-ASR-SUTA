{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allens/anaconda3/envs/tta/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import whisper\n",
    "from whisper.audio import (\n",
    "    log_mel_spectrogram,\n",
    "    pad_or_trim,\n",
    ")\n",
    "import jiwer\n",
    "from tqdm import tqdm\n",
    "from main import *\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 37,184,256 parameters.\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"tiny.en\")\n",
    "print(\n",
    "    # f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
    "    f\"Model has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_params(model):\n",
    "    # collect trainable params\n",
    "    params = []\n",
    "    names = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for nm, m in model.named_modules():\n",
    "        trainable = ['weight', 'bias']\n",
    "        # train_LN\n",
    "        if isinstance(m, nn.LayerNorm) and str(nm).split('.')[0] == 'encoder':\n",
    "            for np, p in m.named_parameters():\n",
    "                if np in trainable:  \n",
    "                    p.requires_grad = True\n",
    "                    params.append(p)\n",
    "                    names.append(f\"{nm}.{np}\")\n",
    "        # train_feature\n",
    "        if len(str(nm).split('.')) > 1:\n",
    "            if str(nm).split('.')[0] == 'encoder' and (str(nm).split('.')[1] == 'conv1' or str(nm).split('.')[1] == 'conv2'):\n",
    "                for np, p in m.named_parameters():\n",
    "                    p.requires_grad = True\n",
    "                    params.append(p)\n",
    "                    names.append(f\"{nm}.{np}\")\n",
    "\n",
    "    return params, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_adapt(x, model, optimizer, em_coef=1.0, reweight=False, temp=1., not_blank=True, scheduler=None, \n",
    "                        div_coef=0, repeat_inference=True, skip_short_thd=None):\n",
    "    \"\"\"Forward and adapt model on batch of data.\n",
    "\n",
    "    Measure entropy of the model prediction, take gradients, and update params.\n",
    "\n",
    "    the index of <pad> in vocab is 0\n",
    "    \"\"\"\n",
    "    # forward\n",
    "    outputs = model.decode(x, options)\n",
    "    logits = torch.stack(outputs[1], dim=0)\n",
    "    logits=logits.permute(1,0,2) # torch.Size([1, 5, 51864])\n",
    "    # adapt\n",
    "    loss = 0\n",
    "\n",
    "    if em_coef > 0: \n",
    "        e_loss = softmax_entropy(logits / temp).mean(0).mean() \n",
    "        \n",
    "        loss += e_loss * em_coef\n",
    "\n",
    "    if 1 - em_coef > 0: \n",
    "        c_loss = mcc_loss(logits / temp, reweight)\n",
    "        loss += c_loss * (1 - em_coef)\n",
    "\n",
    "    if div_coef > 0: \n",
    "        d_loss = div_loss(logits, not_blank) \n",
    "        loss += d_loss * div_coef \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if scheduler is not None: \n",
    "        scheduler.step()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # inference again\n",
    "    if repeat_inference:\n",
    "        with torch.no_grad():\n",
    "            outputs = model.decode(x, options)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]    optimizer: <class 'torch.optim.adamw.AdamW'>\n",
      "[INFO]    scheduler: None\n"
     ]
    }
   ],
   "source": [
    "params, names = collect_params(model)\n",
    "model = model.to(DEVICE)\n",
    "options = whisper.DecodingOptions(language=\"en\", without_timestamps=True)\n",
    "optimizer, scheduler = setup_optimizer(params, 'AdamW', lr=3e-4, scheduler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read text:   0%|          | 0/2939 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read text: 100%|██████████| 2939/2939 [00:00<00:00, 70249.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]    There are 2939 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data import load_dataset\n",
    "dataset = load_dataset(split=['test-other'], name='librispeech', path='../LibriSpeech', batch_size=1, extra_noise=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2939 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2939 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 11.72 GiB of which 48.69 MiB is free. Including non-PyTorch memory, this process has 11.29 GiB memory in use. Of the allocated memory 11.01 GiB is allocated by PyTorch, and 84.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model, optimizer, scheduler \u001b[38;5;241m=\u001b[39m load_model_and_optimizer(model, optimizer, scheduler, model_state, optimizer_state, scheduler_state)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     adapt_output \u001b[38;5;241m=\u001b[39m \u001b[43mforward_and_adapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m transcriptions\u001b[38;5;241m.\u001b[39mappend(adapt_output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     15\u001b[0m ori_transcriptions\u001b[38;5;241m.\u001b[39mappend(texts[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mforward_and_adapt\u001b[0;34m(x, model, optimizer, em_coef, reweight, temp, not_blank, scheduler, div_coef, repeat_inference, skip_short_thd)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward and adapt model on batch of data.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mMeasure entropy of the model prediction, take gradients, and update params.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03mthe index of <pad> in vocab is 0\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(outputs[\u001b[38;5;241m1\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m logits\u001b[38;5;241m=\u001b[39mlogits\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# torch.Size([1, 5, 51864])\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Test-time-adaptation-ASR-SUTA/whisper/decoding.py:827\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    825\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 827\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/Test-time-adaptation-ASR-SUTA/whisper/decoding.py:740\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    737\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m tokens, sum_logprobs, no_speech_probs, logits_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[1;32m    743\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[0;32m~/Desktop/Test-time-adaptation-ASR-SUTA/whisper/decoding.py:688\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[0;32m--> 688\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (1,2,51864)\u001b[39;00m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[1;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Test-time-adaptation-ASR-SUTA/whisper/decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tta/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tta/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Test-time-adaptation-ASR-SUTA/whisper/model.py:215\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    211\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x, xa, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)\n\u001b[1;32m    213\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m    214\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 215\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacty of 11.72 GiB of which 48.69 MiB is free. Including non-PyTorch memory, this process has 11.29 GiB memory in use. Of the allocated memory 11.01 GiB is allocated by PyTorch, and 84.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "transcriptions = []\n",
    "ori_transcriptions = []\n",
    "model_state, optimizer_state, scheduler_state = copy_model_and_optimizer(model, optimizer, scheduler)\n",
    "for batch in tqdm(dataset):\n",
    "    lens, wavs, texts, files = batch\n",
    "    wavs = pad_or_trim(wavs[0])\n",
    "    mel = log_mel_spectrogram(wavs)\n",
    "    mel = mel.unsqueeze(-1)\n",
    "    mel = mel.permute(2,0,1).to(DEVICE)\n",
    "    outputs = model.decode(mel, options)\n",
    "    model, optimizer, scheduler = load_model_and_optimizer(model, optimizer, scheduler, model_state, optimizer_state, scheduler_state)\n",
    "    for i in range(10):\n",
    "        adapt_output = forward_and_adapt(mel, model, optimizer)\n",
    "    transcriptions.append(adapt_output[0][0].text)\n",
    "    ori_transcriptions.append(texts[0])\n",
    "    del outputs, adapt_output\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 130/2620 [04:23<1:24:03,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "transcriptions = []\n",
    "ori_transcriptions = []\n",
    "model_state, optimizer_state, scheduler_state = copy_model_and_optimizer(model, optimizer, scheduler)\n",
    "count = 0\n",
    "for mels, texts in tqdm(loader):\n",
    "    count+=1\n",
    "    if count > 130:\n",
    "        break\n",
    "    outputs = model.decode(mels, options)\n",
    "    model, optimizer, scheduler = load_model_and_optimizer(model, optimizer, scheduler, model_state, optimizer_state, scheduler_state)\n",
    "    for i in range(10):\n",
    "        adapt_output = forward_and_adapt(mels, model, optimizer)\n",
    "    transcriptions.append(adapt_output[0][0].text)\n",
    "    ori_transcriptions.append(texts[0])\n",
    "    del outputs, adapt_output\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuff it into you. His belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall, the yellow lamps would ...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, Bertie. Any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10, fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>I'm me.</td>\n",
       "      <td>AY ME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>No matter then, although my foot did stand, up...</td>\n",
       "      <td>NO MATTER THEN ALTHOUGH MY FOOT DID STAND UPON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Thought kills me that I am not thought, to lea...</td>\n",
       "      <td>THOUGHT KILLS ME THAT I AM NOT THOUGHT TO LEAP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>My heart-doth plead that thou in him-doth lie....</td>\n",
       "      <td>MY HEART DOTH PLEAD THAT THOU IN HIM DOST LIE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>You are my all the world, and I must strive to...</td>\n",
       "      <td>YOU ARE MY ALL THE WORLD AND I MUST STRIVE TO ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hypothesis  \\\n",
       "0    He hoped there would be stew for dinner, turni...   \n",
       "1          Stuff it into you. His belly counseled him.   \n",
       "2    After early nightfall, the yellow lamps would ...   \n",
       "3                Hello, Bertie. Any good in your mind?   \n",
       "4    Number 10, fresh Nelly is waiting on you. Good...   \n",
       "..                                                 ...   \n",
       "125                                            I'm me.   \n",
       "126  No matter then, although my foot did stand, up...   \n",
       "127  Thought kills me that I am not thought, to lea...   \n",
       "128  My heart-doth plead that thou in him-doth lie....   \n",
       "129  You are my all the world, and I must strive to...   \n",
       "\n",
       "                                             reference  \n",
       "0    HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...  \n",
       "1           STUFF IT INTO YOU HIS BELLY COUNSELLED HIM  \n",
       "2    AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...  \n",
       "3                   HELLO BERTIE ANY GOOD IN YOUR MIND  \n",
       "4    NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...  \n",
       "..                                                 ...  \n",
       "125                                              AY ME  \n",
       "126  NO MATTER THEN ALTHOUGH MY FOOT DID STAND UPON...  \n",
       "127  THOUGHT KILLS ME THAT I AM NOT THOUGHT TO LEAP...  \n",
       "128  MY HEART DOTH PLEAD THAT THOU IN HIM DOST LIE ...  \n",
       "129  YOU ARE MY ALL THE WORLD AND I MUST STRIVE TO ...  \n",
       "\n",
       "[130 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(dict(hypothesis=transcriptions, reference=ori_transcriptions))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jiwer\n",
    "from whisper.normalizers import EnglishTextNormalizer\n",
    "\n",
    "normalizer = EnglishTextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>reference</th>\n",
       "      <th>hypothesis_clean</th>\n",
       "      <th>reference_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He hoped there would be stew for dinner, turni...</td>\n",
       "      <td>HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "      <td>he hoped there would be stew for dinner turnip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stuff it into you. His belly counseled him.</td>\n",
       "      <td>STUFF IT INTO YOU HIS BELLY COUNSELLED HIM</td>\n",
       "      <td>stuff it into you his belly counseled him</td>\n",
       "      <td>stuff it into you his belly counseled him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After early nightfall, the yellow lamps would ...</td>\n",
       "      <td>AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "      <td>after early nightfall the yellow lamps would l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, Bertie. Any good in your mind?</td>\n",
       "      <td>HELLO BERTIE ANY GOOD IN YOUR MIND</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "      <td>hello bertie any good in your mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Number 10, fresh Nelly is waiting on you. Good...</td>\n",
       "      <td>NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "      <td>number 10 fresh nelly is waiting on you good n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>I'm me.</td>\n",
       "      <td>AY ME</td>\n",
       "      <td>i am me</td>\n",
       "      <td>ay me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>No matter then, although my foot did stand, up...</td>\n",
       "      <td>NO MATTER THEN ALTHOUGH MY FOOT DID STAND UPON...</td>\n",
       "      <td>no matter then although my foot did stand upon...</td>\n",
       "      <td>no matter then although my foot did stand upon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Thought kills me that I am not thought, to lea...</td>\n",
       "      <td>THOUGHT KILLS ME THAT I AM NOT THOUGHT TO LEAP...</td>\n",
       "      <td>thought kills me that i am not thought to leap...</td>\n",
       "      <td>thought kills me that i am not thought to leap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>My heart-doth plead that thou in him-doth lie....</td>\n",
       "      <td>MY HEART DOTH PLEAD THAT THOU IN HIM DOST LIE ...</td>\n",
       "      <td>my heart doth plead that thou in him doth lie ...</td>\n",
       "      <td>my heart doth plead that thou in him dost lie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>You are my all the world, and I must strive to...</td>\n",
       "      <td>YOU ARE MY ALL THE WORLD AND I MUST STRIVE TO ...</td>\n",
       "      <td>you are my all the world and i must strive to ...</td>\n",
       "      <td>you are my all the world and i must strive to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            hypothesis  \\\n",
       "0    He hoped there would be stew for dinner, turni...   \n",
       "1          Stuff it into you. His belly counseled him.   \n",
       "2    After early nightfall, the yellow lamps would ...   \n",
       "3                Hello, Bertie. Any good in your mind?   \n",
       "4    Number 10, fresh Nelly is waiting on you. Good...   \n",
       "..                                                 ...   \n",
       "125                                            I'm me.   \n",
       "126  No matter then, although my foot did stand, up...   \n",
       "127  Thought kills me that I am not thought, to lea...   \n",
       "128  My heart-doth plead that thou in him-doth lie....   \n",
       "129  You are my all the world, and I must strive to...   \n",
       "\n",
       "                                             reference  \\\n",
       "0    HE HOPED THERE WOULD BE STEW FOR DINNER TURNIP...   \n",
       "1           STUFF IT INTO YOU HIS BELLY COUNSELLED HIM   \n",
       "2    AFTER EARLY NIGHTFALL THE YELLOW LAMPS WOULD L...   \n",
       "3                   HELLO BERTIE ANY GOOD IN YOUR MIND   \n",
       "4    NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD ...   \n",
       "..                                                 ...   \n",
       "125                                              AY ME   \n",
       "126  NO MATTER THEN ALTHOUGH MY FOOT DID STAND UPON...   \n",
       "127  THOUGHT KILLS ME THAT I AM NOT THOUGHT TO LEAP...   \n",
       "128  MY HEART DOTH PLEAD THAT THOU IN HIM DOST LIE ...   \n",
       "129  YOU ARE MY ALL THE WORLD AND I MUST STRIVE TO ...   \n",
       "\n",
       "                                      hypothesis_clean  \\\n",
       "0    he hoped there would be stew for dinner turnip...   \n",
       "1            stuff it into you his belly counseled him   \n",
       "2    after early nightfall the yellow lamps would l...   \n",
       "3                   hello bertie any good in your mind   \n",
       "4    number 10 fresh nelly is waiting on you good n...   \n",
       "..                                                 ...   \n",
       "125                                            i am me   \n",
       "126  no matter then although my foot did stand upon...   \n",
       "127  thought kills me that i am not thought to leap...   \n",
       "128  my heart doth plead that thou in him doth lie ...   \n",
       "129  you are my all the world and i must strive to ...   \n",
       "\n",
       "                                       reference_clean  \n",
       "0    he hoped there would be stew for dinner turnip...  \n",
       "1            stuff it into you his belly counseled him  \n",
       "2    after early nightfall the yellow lamps would l...  \n",
       "3                   hello bertie any good in your mind  \n",
       "4    number 10 fresh nelly is waiting on you good n...  \n",
       "..                                                 ...  \n",
       "125                                              ay me  \n",
       "126  no matter then although my foot did stand upon...  \n",
       "127  thought kills me that i am not thought to leap...  \n",
       "128  my heart doth plead that thou in him dost lie ...  \n",
       "129  you are my all the world and i must strive to ...  \n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hypothesis_clean\"] = [normalizer(text) for text in data[\"hypothesis\"]]\n",
    "data[\"reference_clean\"] = [normalizer(text) for text in data[\"reference\"]]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 4.72 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 4.27 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 3.05 %\n"
     ]
    }
   ],
   "source": [
    "wer = jiwer.wer(list(data[\"reference_clean\"]), list(data[\"hypothesis_clean\"]))\n",
    "\n",
    "print(f\"WER: {wer * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
